{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Required Libraries"
      ],
      "metadata": {
        "id": "OUehTAvTEhmB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ogu7QU0tjIOe"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 8, 0)\n",
        "assert sys.version_info < (3, 9, 0)\n",
        "import json\n",
        "import pandas as pd\n",
        "from jenga.corruptions.generic import MissingValues\n",
        "from jenga.corruptions.generic import CategoricalShift\n",
        "from jenga.corruptions.generic import SwappedValues\n",
        "from jenga.corruptions.numerical import Scaling\n",
        "from jenga.corruptions.numerical import GaussianNoise\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import resample\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "import miceforest as mf\n",
        "import pandas as pd\n",
        "import json\n",
        "import jenga\n",
        "import random\n",
        "import jamspell\n",
        "import time\n",
        "from joblib import dump\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Injections (Categorical and Numerical)"
      ],
      "metadata": {
        "id": "zuDpsYdzEqdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def missing_values(df, column, fraction=.5, missingness='MCAR'):\n",
        "    df[column] = MissingValues(column=column, fraction=fraction, missingness=missingness).transform(df)[column]\n",
        "    return df\n",
        "\n",
        "def swapping_values(df, column1, column2, fraction=.5, missingness='MCAR'):\n",
        "  print(df.columns)\n",
        "  print(column1, column2)\n",
        "  df = SwappedValues(column=column1, fraction=fraction, sampling=missingness, swap_with=column2).transform(df)\n",
        "  return df\n",
        "\n",
        "def permute_categories(df, column, fraction=.5, missingness='MAR'):\n",
        "    df[column] = CategoricalShift(column=column, fraction=fraction, sampling=missingness).transform(df)[column]\n",
        "    return df\n",
        "\n",
        "def scale(df, column, fraction=.5, missingness='MCAR'):\n",
        "  df[column] = df[column].astype(str)\n",
        "  parts = df[column].str.extract(r'^(\\D*?)(\\d+\\.*\\d*)(.*)')\n",
        "  parts[1] = parts[1].astype(float)\n",
        "  parts[1] = Scaling(column = 1, fraction =fraction, sampling=missingness).transform(parts)[1]\n",
        "\n",
        "  # Append non-numerical part to numerical part\n",
        "  combined_values = parts[0] + parts[1].astype(str) + parts[2]\n",
        "\n",
        "  df[column] = combined_values\n",
        "  return df"
      ],
      "metadata": {
        "id": "9Dmry0vNcJPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Textual Error Injections"
      ],
      "metadata": {
        "id": "s53vKGC8E5DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qwerty_dic = {'a': 'qwsz', 'b': 'vghn', 'c': 'xdfv', 'd': 'serfcx', 'e': 'wsdfr', 'f': 'drtgvc', 'g': 'ftyhbv', 'h': 'gyujnb', 'i': 'uojk', 'j': 'uikmnh', 'k': 'ijlm', 'l': 'opk', 'm': 'njk,', 'n': 'bhjm', 'o': 'iklp', 'p': 'ol', 'q': 'was', 'r': 'edft', 's': 'awedxz', 't': 'rfgy', 'u': 'yhji', 'v': 'cfgb', 'w': 'qesa', 'x': 'zsdc', 'y': 'tghu', 'z': 'asx'}\n",
        "\n",
        "def inject_typo_naive(text, prob=0.1):\n",
        "    typo = \"\"\n",
        "    for char in text:\n",
        "        if random.random() < prob and char != ' ':\n",
        "            typo += random.choice('abcdefghijklmnopqrstuvwxyz')\n",
        "        else:\n",
        "            typo += char\n",
        "    return typo\n",
        "\n",
        "def inject_typo_typographic(text, dic=qwerty_dic, typo_prob=0.1, adjac_prob = 0.8):\n",
        "    typo = \"\"\n",
        "    for char in text:\n",
        "        if random.random() < typo_prob and char != ' ':\n",
        "          if (char in dic) and (random.random() < adjac_prob):\n",
        "            typo += random.choice(dic[char])\n",
        "          else:\n",
        "            typo += random.choice('abcdefghijklmnopqrstuvwxyz')\n",
        "        else:\n",
        "            typo += char\n",
        "    return typo\n",
        "\n",
        "def naive_typo_df(df, columns, prob):\n",
        "  for col in columns:\n",
        "    df[col] = df[col].apply(inject_typo_naive,prob=prob)\n",
        "  return df\n",
        "\n",
        "def inject_typo_df(df, columns, prob):\n",
        "  for col in columns:\n",
        "    df[col] = df[col].apply(inject_typo_typographic,typo_prob=prob)\n",
        "  return df"
      ],
      "metadata": {
        "id": "DCLo5O1lodo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Injections (Combined)\n",
        "This function is used to inject errors into a dataframe.\n",
        "It takes:\n",
        "* The dataframe\n",
        "* a list of error tuples\n",
        "  * This list has the following format:\\\n",
        "  [ \\\n",
        "  (*name_of_error_1*, [*name_of_column_for_error_1*]), \\\n",
        "  (*name_of_error_2*, [*name_of_column_for_error_2*]), \\\n",
        "  (etc.) \\\n",
        "  ] \\\n",
        "  each tuple in this list represents 1 error to be applied to 1 column (some errors require two columns to be passed in the list in the second part of the tuple like swapping).\n",
        "  * For example if you want to apply the missing value error to columns 'age' and 'review_text' and the swap the columns 'height' and 'weight' the errors list would look like:\\\n",
        "  [ \\\n",
        "  ('missing', ['age']), \\\n",
        "  ('missing', ['review_text']), \\\n",
        "  ('swapping', ['height', 'weight'])\\\n",
        "  ] \\\n",
        "* a fraction of the rows to which to apply the errors\n",
        "* If verbose is set to True it will print, for each error, the column before and after the corruption\n",
        "\n",
        "It returns:\n",
        "* The corrupted dataframe\n",
        "\n",
        "\n",
        "Possible error names:\n",
        "\n",
        "* 'missing': Inject issing values\n",
        "* 'swapping' : Swap the values oftwo columns(takes two column names)\n",
        "* 'category_mixup': Permute the categorical values of a column: 'category_mixup'\n",
        "* 'noise': Add noise and rounding to numerical column\n",
        "* 'scale' : Randomly Scales a numerical columns\n",
        "* 'manual_typo': Typo injection into textual columns (currently doesnt support the fraction parameter)\n"
      ],
      "metadata": {
        "id": "947Tjb7yGivb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inject errors into a Dataframe\n",
        "def inject_error(df, errors, fraction=0.5, verbose=True):\n",
        "\n",
        "    for error, args in errors:\n",
        "      error_df = pd.DataFrame()\n",
        "      error_df['before_error'] = df[args[0]]\n",
        "      print(f\"injecting error '{error}' on {fraction*100}% of column '{args[0]}' (args = {args})\")\n",
        "\n",
        "      # ('missing', [column, fraction, missingess])\n",
        "      if error == 'missing':\n",
        "        df = missing_values(df, args[0], fraction=fraction)\n",
        "      # ('swapping', [column1, column2, fraction, missingess])\n",
        "      elif error == 'swapping':\n",
        "        df = swapping_values(df, args[0], args[1], fraction=fraction)\n",
        "      elif error == 'category_mixup':\n",
        "        df = permute_categories(df, args[0], fraction=fraction)\n",
        "      elif error ==  'noise':\n",
        "        df = noise_and_rounding(df, args[0], fraction=fraction)\n",
        "      elif error ==  'scale':\n",
        "        df = scale(df, args[0], fraction=fraction)\n",
        "      elif error == 'typo_smart':\n",
        "        df = naive_typo_df(df, [args[0]],0.1)\n",
        "      elif error == 'typo_naive':\n",
        "        df = naive_typo_df(df, [args[0]],0.1)\n",
        "\n",
        "      error_df['after_error'] = df[args[0]]\n",
        "\n",
        "      if verbose:\n",
        "        print(error_df)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "ZZIxaq39GmbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing functions"
      ],
      "metadata": {
        "id": "HhgI40h2FGah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_cat = OneHotEncoder(handle_unknown='ignore')\n",
        "# encoder = ce.QuantileEncoder(cols=['bust size', 'category'], quantile=0.5, m=1.0)\n",
        "tar_enc = ce.MEstimateEncoder(cols=['bust_size', 'category'], m=5.0)\n",
        "\n",
        "def prepare_categorical(df, columns1, columns2, column_y, data_type):\n",
        "\n",
        "    if data_type == \"train\":\n",
        "      # Convert target mapping to numeric data\n",
        "      mapping = {'fit': 1, 'small': 2, 'large': 3}\n",
        "      new_df = df.copy()\n",
        "      # Replace the values using the mapping in the new DataFrame\n",
        "      new_df[column_y] = df[column_y].replace(mapping)\n",
        "\n",
        "      global enc_bs, enc_cat1\n",
        "      enc_cat1 = enc_cat.fit(df[columns1])\n",
        "      enc_bs = tar_enc.fit(new_df[columns2], new_df[column_y])\n",
        "\n",
        "    enc_df1 = pd.DataFrame(enc_cat1.transform(df[columns1]).toarray(), columns=enc_cat1.get_feature_names_out(columns1))\n",
        "    # enc_df1 = pd.DataFrame(enc_cat1.transform(df[columns1]).toarray(), columns=enc_cat1.get_feature_names(input_features=columns1))\n",
        "    enc_df2 = enc_bs.transform(df[columns2])\n",
        "\n",
        "    df.drop(columns=columns1, inplace=True)\n",
        "    df.drop(columns=columns2, inplace=True)\n",
        "    df = pd.concat([df, enc_df1, enc_df2], axis=1)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "RtqkpPCgFRxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare numerical data\n",
        "sc = StandardScaler()\n",
        "\n",
        "def prepare_numerical(df, numerical_columns, data_type):\n",
        "    for col in numerical_columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    if data_type == \"train\":\n",
        "      global enc_num\n",
        "      enc_num = sc.fit(df[numerical_columns])\n",
        "\n",
        "    sc_df = pd.DataFrame(enc_num.transform(df[numerical_columns]), columns=numerical_columns)\n",
        "\n",
        "    df.drop(columns=numerical_columns, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    sc_df.reset_index(drop=True, inplace=True)\n",
        "    df = pd.concat([df, sc_df], axis=1)\n",
        "    df.drop(columns=numerical_columns, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "uBay5OXeFSoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_cm(height):\n",
        "    if pd.isna(height):\n",
        "        return pd.NA\n",
        "    height = str(height)\n",
        "\n",
        "    if not(re.match(r'^\\d+\\'\\s*\\d+\\\"$', height)):\n",
        "      numeric = re.findall(r'\\d+', height)\n",
        "      if len(numeric) > 0:\n",
        "        return numeric[0]\n",
        "      else:\n",
        "        return pd.NA\n",
        "\n",
        "    ft, inches = height.split(\"'\")\n",
        "    total = int(float(ft)) * 12 + int(inches.replace('\"', ''))\n",
        "    return total * 2.54"
      ],
      "metadata": {
        "id": "V_IHdA6QjyO-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare text columns\n",
        "enc = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "def prepare_text(df, text_columns, target_column, data_type):\n",
        "    corpus = df[text_columns].apply(lambda x: ' '.join(map(str, x)), axis=1)\n",
        "\n",
        "    if data_type == \"train\":\n",
        "      global enc_txt\n",
        "      enc_txt = enc.fit(corpus)\n",
        "\n",
        "    # enc_df = pd.DataFrame(enc_txt.transform(corpus).toarray(), columns=enc.get_feature_names())\n",
        "    enc_df = pd.DataFrame(enc.fit_transform(corpus).toarray(), columns=enc.get_feature_names_out())\n",
        "    #enc_df = enc_df.rename(columns={target_column: 'tf_' + target_column})\n",
        "\n",
        "    enc_df.columns = ['tf_' + col for col in enc_df.columns]\n",
        "\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    enc_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    df = pd.concat([df, enc_df], axis=1)\n",
        "    df.drop(columns=text_columns, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "0nyB0f1eFhnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic preprocessing\n",
        "\n",
        "# Cardinality <10\n",
        "categorical_columns1 = ['rented_for', 'body_type']\n",
        "# Cardinality >10\n",
        "categorical_columns2 = ['bust_size', 'category']\n",
        "numerical_columns = ['rating', 'weight', 'height', 'size', 'age', 'Year', 'Month', 'Day']\n",
        "text_columns = ['review_text', 'review_summary']\n",
        "target_column = 'fit'\n",
        "columns_to_drop = ['item_id', 'user_id', 'review_date']\n",
        "\n",
        "def basic_preproseccing(df, data_type):\n",
        "  for column in list(set(numerical_columns) - set(['height' , 'Year', 'Month', 'Day'])):\n",
        "    df[column] = df[column].astype(str).str.extract('(\\d+)').astype(float)\n",
        "\n",
        "  df['height'] = df['height'].apply(convert_to_cm)\n",
        "  df['review_date'] = pd.to_datetime(df['review_date'])\n",
        "  df['Year'] = df['review_date'].dt.year\n",
        "  df['Month'] = df['review_date'].dt.month\n",
        "  df['Day'] = df['review_date'].dt.day\n",
        "\n",
        "\n",
        "  df = prepare_numerical(df, numerical_columns, data_type)\n",
        "  df = prepare_categorical(df, categorical_columns1, categorical_columns2, target_column, data_type)\n",
        "  df = prepare_text(df, text_columns, target_column, data_type)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "UOBzklf8Fnrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing required for Mice forest\n",
        "def miceprec(df):\n",
        "  numerical_columns = ['rating', 'weight', 'height', 'size', 'age']\n",
        "  for column in list(set(numerical_columns) - set(['height'])):\n",
        "      df[column] = df[column].astype(str).str.extract('(\\d+)').astype(float)\n",
        "  df['height'] = df['height'].apply(convert_to_cm)"
      ],
      "metadata": {
        "id": "6gK7T0sgG69b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and Splitting Dataset"
      ],
      "metadata": {
        "id": "DrF8i5XFFq6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function Splits the data set into a train and test set. It resamples the dataframe so that it is balanced with respect to the values of the target variable. It also fits the preprocessers to the training data, and applies the preprocessing to the training data aswell. It returns the preprocessed training data and the unprocessed testing data."
      ],
      "metadata": {
        "id": "hmSrwcBxMCOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This function loads the data from file and splits it into train/test sets\n",
        "# it also preprocesses the training set\n",
        "def split_data(random_state = None, verbose = True):\n",
        "  start_split = time.time()\n",
        "  df = pd.read_json('renttherunway_final_data.json', lines=True)\n",
        "\n",
        "  # Removing spaces in column names\n",
        "  df.columns = df.columns.str.replace(' ', '_')\n",
        "\n",
        "  # Assuming your DataFrame is called df and the target column is called 'target'\n",
        "  # You'll need to replace 'target_class1', 'target_class2', and 'target_class3' with the actual class labels in your dataset\n",
        "\n",
        "  # Separate majority and minority classes\n",
        "  majority_class = df[df['fit'] == 'fit']\n",
        "  minority_class1 = df[df['fit'] == 'small']\n",
        "  minority_class2 = df[df['fit'] == 'large']\n",
        "\n",
        "  # Downsample majority class to match minority class sizes\n",
        "  majority_downsampled = resample(majority_class,\n",
        "                                  replace=False,  # sample without replacement\n",
        "                                  n_samples=len(minority_class2),  # match minority class 1 size\n",
        "                                  random_state=42)  # reproducible results\n",
        "\n",
        "  # Downsample majority class to match minority class sizes\n",
        "  minority_downsampled_2 = resample(minority_class1,\n",
        "                                  replace=False,  # sample without replacement\n",
        "                                  n_samples=len(minority_class2),  # match minority class 2 size\n",
        "                                  random_state=42)  # reproducible results\n",
        "\n",
        "  # Combine minority classes with downsampled majority class\n",
        "  balanced_df = pd.concat([majority_downsampled, minority_downsampled_2, minority_class2])\n",
        "\n",
        "  # Shuffle the DataFrame to mix the classes\n",
        "  balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "  balanced_df['fit'].value_counts()\n",
        "\n",
        "  df = balanced_df\n",
        "\n",
        "  if verbose:\n",
        "    print_stats(df)\n",
        "\n",
        "\n",
        "  X = df.drop(columns=[target_column])\n",
        "  y = df[target_column]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "  end_split = time.time()\n",
        "\n",
        "  print(f\"Splitting training data took {end_split - start_split}s\")\n",
        "\n",
        "  train = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "  start_train_preprocess = time.time()\n",
        "  train = basic_preproseccing(train, 'train')\n",
        "\n",
        "  X_train = train.drop(columns= columns_to_drop + [target_column])\n",
        "\n",
        "  y_train = train[target_column]\n",
        "  end_train_preprocess = time.time()\n",
        "\n",
        "  print(f\"preprocessing training data took {end_train_preprocess - start_train_preprocess}s\")\n",
        "\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "rJftBiw_FsgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AutoFix"
      ],
      "metadata": {
        "id": "QKgZgIcRFXAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class metadata:\n",
        "    def determine_column_types(self,df):\n",
        "        self.categorical_features = {}\n",
        "        self.numerical_features = {}\n",
        "        self.text_features = {}\n",
        "        for x in df:\n",
        "            if(len(pd.unique(df[x])) != len(df[x])):\n",
        "                if(\"id\" in x):\n",
        "                    continue\n",
        "                if(is_numeric_dtype(df[x])):\n",
        "                    self.numerical_features[x] = {\"clean\": 100 - ((df[x].isna().sum() / len(df[x])) * 100), \"unique\" : len(pd.unique(df[x]))}\n",
        "                elif(len(pd.unique(df[x])) <= 200):\n",
        "                    self.categorical_features[x] = {\"clean\": 100 - ((df[x].isna().sum() / len(df[x])) * 100), \"unique\" : len(pd.unique(df[x]))}\n",
        "                elif(isinstance(df[x].iloc[0], str)):\n",
        "                    self.text_features[x] = {\"clean\": 100 - ((df[x].isna().sum() / len(df[x])) * 100), \"unique\" : len(pd.unique(df[x]))}\n",
        "\n",
        "    def __init__(self,df):\n",
        "        self.determine_column_types(df)\n",
        "\n",
        "class autofix:\n",
        "    def preprocess(self):\n",
        "        for column in self.df:\n",
        "            self.df.rename(columns={column : column.replace(\" \", \"_\")}, inplace = True)\n",
        "        for column in self.df:\n",
        "            if(isinstance(self.df[column].iloc[0], str)):\n",
        "                if(np.sum(self.df[column].str.isnumeric()) == len(self.df[column])):\n",
        "                    self.df[column] = self.df[column].astype(int)\n",
        "                elif(np.sum(self.df[column].replace(\".\", \"\").str.isnumeric()) == len(self.df[column])):\n",
        "                    self.df[column] = self.df[column].astype(float)\n",
        "\n",
        "    def correct_typo(self, columns, verbose=True):\n",
        "        tot_time = 0\n",
        "        for i in range(len(columns)):\n",
        "            col = columns[i]\n",
        "            if verbose:\n",
        "                print(f\"Correcting typos in column {i+1}/{len(columns)} ({self.df[col].shape[0]} rows)...\")\n",
        "            start = time.time()\n",
        "            try:\n",
        "                self.df[col]=self.df[col].apply(self.corrector.FixFragment)\n",
        "            except:\n",
        "                print(f\"Error correcting typos in column {i+1}. Aborting.\")\n",
        "                return\n",
        "\n",
        "            end = time.time()\n",
        "            if verbose:\n",
        "                print(f\"Finished correcting typos in column {i+1}. Time taken: {end - start}s\")\n",
        "            tot_time += (end - start)\n",
        "        if verbose:\n",
        "            print(f\"Finished correcting typos. Total time taken: {tot_time}s\")\n",
        "\n",
        "    def miceforest_imputer(self):\n",
        "        # Determine the column types and columns to drop before imputation\n",
        "        columns_to_drop = ['item_id', 'user_id', 'review_date', 'fit','review_text', 'review_summary','Year', 'Month', 'Day']\n",
        "        categorical_columns = ['rented_for', 'body_type','bust_size', 'category']\n",
        "        numerical_columns = ['rating', 'weight', 'height', 'size', 'age']\n",
        "\n",
        "        # Take a copy of self.df prior to dropping non-numerical and non-categorical\n",
        "        df2 = self.df.copy()\n",
        "        # Drop the specified columns from df2\n",
        "        for col in columns_to_drop:\n",
        "            df2 = df2.drop(columns=col, errors='ignore')\n",
        "\n",
        "        # Set the data types for categorical and numerical columns\n",
        "        df2[categorical_columns] = df2[categorical_columns].astype('category')\n",
        "        for col in numerical_columns:\n",
        "            df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
        "\n",
        "        # Create kernels.  #mice forest\n",
        "        kernel = mf.ImputationKernel(\n",
        "          data=df2,\n",
        "          save_all_iterations=True,\n",
        "          random_state=1343\n",
        "        )\n",
        "        # Run the MICE algorithm for 3 iterations on each of the datasets\n",
        "        kernel.mice(1,verbose=True, n_estimators=50)\n",
        "        completed_dataset = kernel.complete_data(dataset=0, inplace=False)\n",
        "\n",
        "\n",
        "        # Drop common columns from self.df\n",
        "        self.df.drop(columns=categorical_columns+numerical_columns, inplace=True)\n",
        "\n",
        "        # Replace dropped columns in df with columns from completed_dataset\n",
        "        self.df[categorical_columns+numerical_columns] = completed_dataset[categorical_columns+numerical_columns]\n",
        "\n",
        "    def bootstrap_imputer(self, df, column_to_predict, clean_mask):\n",
        "        if(np.sum(clean_mask) == len(df)):\n",
        "            return df\n",
        "        features_to_subset = set(self.metadata.categorical_features.keys())\n",
        "        features_to_subset.discard(column_to_predict)\n",
        "        features_to_subset.difference_update(self.features_to_exclude)\n",
        "        dirty_mask = ~clean_mask\n",
        "        clean_data = df.loc[clean_mask]\n",
        "        dirty_data = df.loc[dirty_mask]\n",
        "        cleaned_index = pd.Index([])\n",
        "        dirty_sizes = dirty_data.groupby(list(features_to_subset)).size().sort_values(ascending=False).reset_index()\n",
        "        if((column_to_predict in list(self.metadata.text_features.keys())) and self.text_fix == \"no\"):\n",
        "            dirty_data[column_to_predict] = \"\"\n",
        "            return pd.concat([clean_data, dirty_data])\n",
        "        elif((column_to_predict in list(self.metadata.text_features.keys())) and self.text_fix == \"drop\"):\n",
        "            return df\n",
        "\n",
        "\n",
        "        for sizes_index in range(len(dirty_sizes)):\n",
        "            if(sizes_index > 100):\n",
        "                break\n",
        "            query = \"\"\n",
        "            for column in features_to_subset:\n",
        "                value = dirty_sizes.loc[sizes_index][column]\n",
        "                is_numeric = isinstance(value,int) | isinstance(value, float)\n",
        "                if(is_numeric):\n",
        "                    query = query + f'{column} == {value} and '\n",
        "                else:\n",
        "                    value = value.replace('\\\"', '\\\\\"')\n",
        "                    query = query + f'{column} == \"{value}\" and '\n",
        "            query = query[:-4]\n",
        "            sample_space = clean_data.query(query)\n",
        "            if(len(sample_space) == 0):\n",
        "                continue\n",
        "            if(column_to_predict in list(self.metadata.numerical_features.keys())):\n",
        "                impute_value = self.get_num_impute_bootstrap_value(sample_space[column_to_predict],self.num_impute_bootstrap)\n",
        "            else:\n",
        "                impute_value = sample_space[column_to_predict].mode()[0]\n",
        "            data_to_impute = dirty_data.query(query)\n",
        "            dirty_data.loc[data_to_impute.index,column_to_predict] = impute_value\n",
        "            cleaned_index = cleaned_index.union(data_to_impute.index)\n",
        "        other_data_index = dirty_data.index.difference(cleaned_index)\n",
        "        if(column_to_predict in list(self.metadata.numerical_features.keys())):\n",
        "            impute_value = self.get_num_impute_bootstrap_value(clean_data[column_to_predict],self.num_impute_bootstrap)\n",
        "        else:\n",
        "            impute_value = clean_data[column_to_predict].mode()[0]\n",
        "        dirty_data.loc[other_data_index,column_to_predict] = impute_value\n",
        "        return pd.concat([clean_data, dirty_data])\n",
        "\n",
        "    def scaling_fix(self,scaling_factors = [1000,100], base_factor = 1):\n",
        "        for column in list(self.metadata.numerical_features.keys()):\n",
        "            min = np.min(self.df[column])\n",
        "            if(min == 0):\n",
        "                min  = 1\n",
        "            for factor in scaling_factors:\n",
        "                mask = self.df[column] >= factor * min\n",
        "                self.df.loc[mask, column] = self.df.loc[mask, column] / factor\n",
        "            self.df[column] = self.df[column] * base_factor\n",
        "\n",
        "\n",
        "    def impute_missing(self):\n",
        "        self.df = self.bootstrap_imputer(self.df, self.best_cat[0],self.df[self.best_cat[0]].notna())\n",
        "        for column in self.df:\n",
        "            if(column != self.best_cat[0]):\n",
        "                self.df= self.bootstrap_imputer(self.df, column, self.df[column].notna())\n",
        "\n",
        "    def __init__(self,df, imputation_type_for_NonTextData=\"bootstrap\", num_impute_bootstrap = \"mode\", text_fix = \"yes\",features_to_exclude = [], typo_fixes = []):\n",
        "        \"\"\" @params:\n",
        "                - df                              = Dataframe to impute\n",
        "                - imputation_type_for_NonTextData = Default imputation is bootstrap\n",
        "                                                    possible_imputation_methods [\"bootstrap\", \"miceforest\"].\n",
        "                                                    MICEForest can be used for categorical and numerical imputations.\n",
        "                                                    Reamining columns will be imputed with bootstrap imputation\n",
        "\n",
        "        \"\"\"\n",
        "        self.imputation_type_for_NonTextData = imputation_type_for_NonTextData\n",
        "        possible_imputation_methods = [\"bootstrap\", \"miceforest\"]\n",
        "\n",
        "        if self.imputation_type_for_NonTextData not in possible_imputation_methods:\n",
        "            raise ValueError(f\"Invalid imputation type: {self.imputation_type_for_NonTextData}. \"\n",
        "                             f\"Allowed imputation methods are: {', '.join(possible_imputation_methods)}\")\n",
        "        self.corrector = jamspell.TSpellCorrector()\n",
        "        self.corrector.LoadLangModel('en.bin')\n",
        "        self.df = df.dropna(thresh = round(0.25 * len(df.columns)))\n",
        "        self.num_impute_bootstrap = num_impute_bootstrap\n",
        "        self.text_fix = text_fix\n",
        "        self.features_to_exclude = features_to_exclude\n",
        "        self.preprocess()\n",
        "        self.metadata = metadata(self.df)\n",
        "        if(len(typo_fixes) == 0):\n",
        "            self.typo_fixes = list(self.metadata.text_features.keys())\n",
        "        else:\n",
        "            self.typo_fixes = typo_fixes\n",
        "\n",
        "    def get_num_impute_bootstrap_value(self, values, method):\n",
        "        if(method == \"mode\"):\n",
        "            return values.mode()[0]\n",
        "        elif(method == \"mean\"):\n",
        "            return values.mean()\n",
        "        else:\n",
        "            return values.median()\n",
        "\n",
        "    def fix(self):\n",
        "        self.correct_typo(self.typo_fixes)\n",
        "        if self.imputation_type_for_NonTextData == \"miceforest\":\n",
        "            print(\"USING MICEFOREST\")\n",
        "            self.miceforest_imputer()\n",
        "        if(self.text_fix == \"drop\"):\n",
        "            self.df = self.df.dropna(subset=list(self.metadata.text_features.keys()))\n",
        "        self.non_text_columns = list(self.metadata.numerical_features.keys()) + list(self.metadata.categorical_features.keys())\n",
        "        self.best_cat = (\"\",0,0)\n",
        "        self.second_best_cat = (\"\",0,0)\n",
        "        for cat in list(self.metadata.categorical_features.keys()):\n",
        "            if ((self.metadata.categorical_features[cat][\"unique\"] > self.best_cat[1]) & (self.metadata.categorical_features[cat][\"clean\"] >= self.best_cat[2])):\n",
        "                self.second_best_cat = self.best_cat\n",
        "                self.best_cat = (cat, self.metadata.categorical_features[cat][\"unique\"],self.metadata.categorical_features[cat][\"clean\"])\n",
        "            elif ((self.metadata.categorical_features[cat][\"unique\"] > self.second_best_cat[1]) & (self.metadata.categorical_features[cat][\"clean\"] >= self.second_best_cat[2])):\n",
        "                self.second_best_cat = (cat, self.metadata.categorical_features[cat][\"unique\"],self.metadata.categorical_features[cat][\"clean\"])\n",
        "        self.impute_missing()\n",
        "        self.scaling_fix()\n",
        "        return self.df"
      ],
      "metadata": {
        "id": "bMld3d1TkYTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AutoFix test\n",
        "\n",
        "reviews = []\n",
        "with open('./renttherunway_final_data.json', 'r') as file:\n",
        "    for line in file:\n",
        "        reviews.append(json.loads(line))\n",
        "df = pd.DataFrame(reviews)\n",
        "df = miceprec(df)\n",
        "\n",
        "print(df)\n",
        "auto_imputer = autofix(df, imputation_type_for_NonTextData='miceforest',typo_fixes=['review_summary'])\n",
        "auto_imputer.fix()\n",
        "output = auto_imputer.df.sort_index()\n",
        "output.dropna()"
      ],
      "metadata": {
        "id": "g4_GygGfGbmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Corrupt & Fix\n",
        "This function allows to run a single experiment on a specific dataset with specific error injections and specific cleaning methods.\n",
        "This function takes:\n",
        "* a trained model\n",
        "* a list of \"error tuples\" which define the errors to be injected into the data\n",
        "* A number between 0 and 1 which defines the fraction of rows to inject the error on\n",
        "* The unprocessed X_test data partition\n",
        "* The y_test data for the accuracy report\n",
        "* The training data that was used to train the model.\n",
        "\n",
        "It returns:\n",
        "* The accuracy report of the experiment (as a dict)"
      ],
      "metadata": {
        "id": "mnfTg_rrHDBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes a model, test_data and a set of errors and applies the errors to the test data.\n",
        "# The model is run on corrupted test data and the accuracy report is returned\n",
        "\n",
        "def corrupt_and_fix(model, errors, X_test, y_test, X_train, y_train, auto=False, verbose=True):\n",
        "\n",
        "  # corrupt test data\n",
        "  start_corruption = time.time()\n",
        "  X_corrupted_test = inject_error(X_test, errors, verbose = verbose)\n",
        "  stop_corruption = time.time()\n",
        "  print(f\"Corruption of test data time: {stop_corruption - start_corruption}s\")\n",
        "\n",
        "  corrupted_test = pd.concat([X_corrupted_test, y_test], axis = 1)\n",
        "\n",
        "\n",
        "  start_cleaning = time.time()\n",
        "\n",
        "  # corrupted\n",
        "  if auto:\n",
        "    corrutped_test = miceprec(corrupted_test)\n",
        "    auto_imputer = autofix(corrupted_test, imputation_type_for_NonTextData='miceforest',typo_fixes=['review_summary'])\n",
        "    auto_imputer.fix()\n",
        "    output = auto_imputer.df.sort_index()\n",
        "    output.dropna()\n",
        "    corrupted_test = output\n",
        "\n",
        "  end_cleaning = time.time()\n",
        "  print(f\"Cleaning of test data time: {end_cleaning - start_cleaning}s\")\n",
        "\n",
        "  # preprocess corrupted data\n",
        "\n",
        "  start_preprocess_test = time.time()\n",
        "  corrupted_test = basic_preproseccing(corrupted_test, 'test')\n",
        "  end_preprocess_test = time.time()\n",
        "  print(f\"Preprocessing of test data time: {end_preprocess_test - start_preprocess_test}s\")\n",
        "\n",
        "  X_corrupted_test = corrupted_test.drop(columns = columns_to_drop +[target_column])\n",
        "\n",
        "  # ensure that the train and test sets have the same columns\n",
        "  X_corrupted_test = X_corrupted_test.filter(items=X_train.columns)\n",
        "  missing_columns = X_train.columns.difference(X_corrupted_test.columns)\n",
        "  X_corrupted_test[missing_columns] = 0\n",
        "\n",
        "  X_corrupted_test = X_corrupted_test[X_train.columns]\n",
        "\n",
        "  y_corrupted_test = corrupted_test[y_test.name]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # use model to predict and return classification report\n",
        "  start_prediction = time.time()\n",
        "  y_corrupted_pred = model.predict(X_corrupted_test)\n",
        "  end_prediction = time.time()\n",
        "  print(f\"Prediction of test data time: {end_prediction - start_prediction}s\")\n",
        "\n",
        "  report = classification_report(y_corrupted_test, y_corrupted_pred, output_dict = True)\n",
        "\n",
        "  print(f\"accuracy is {report['accuracy']}\")\n",
        "  return report"
      ],
      "metadata": {
        "id": "xil7RTVCmeWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "\n",
        "This cell pretrains 5 models for later use (since the same set of random states are used across experiments, we are ables to split the data, and train the models in advance and there is no need to do that at runtime). It loads 5 lists. One with the trained models, and then four with the verious dataset partitions. X_train and y_train are already preprocessed after running this cell. X_test and y_test are not."
      ],
      "metadata": {
        "id": "vq4W2yS1Hye4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_states = [4, 256, 32, 42, 1]\n",
        "models = []\n",
        "X_tests = []\n",
        "y_tests = []\n",
        "X_trains = []\n",
        "y_trains = []\n",
        "\n",
        "\n",
        "for i in range(len(random_states)):\n",
        "  print(f\"preparing model {i+1} of {len(random_states)}\")\n",
        "  X_train, X_test, y_train, y_test = split_data(random_state=random_states[i], verbose = False)\n",
        "\n",
        "  X_tests.append(X_test)\n",
        "  y_tests.append(y_test)\n",
        "  X_trains.append(X_train)\n",
        "  y_trains.append(y_train)\n",
        "\n",
        "  model = RandomForestClassifier()\n",
        "  start = time.time()\n",
        "  model.fit(X_train, y_train)\n",
        "  stop = time.time()\n",
        "  print(f\"Training time: {stop - start}s\")\n",
        "\n",
        "  models.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmVVyZM-mxEl",
        "outputId": "f00e0ee4-c318-4742-9997-ca4eb6c0fda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing model 1 of 5\n",
            "Splitting training data took 1.6774237155914307s\n",
            "preprocessing training data took 3.991675853729248s\n",
            "Training time: 36.39355421066284s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(random_states)):\n",
        "  dump(models[i], (f'model_state_{random_states[i]}.joblib'))"
      ],
      "metadata": {
        "id": "pMxZvp8pm7B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collecting Results"
      ],
      "metadata": {
        "id": "ZH9uW0PdH3Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_report(file, mode):\n",
        "  test_outcome_df = pd.DataFrame(columns = [\"precision\", \"recall\", \"f1\", \"support\", \"error tuple\", \"random state\"])\n",
        "  test_outcome_df.to_csv(file, mode=mode)\n",
        "\n",
        "def append_report(report, file, random_state, errors):\n",
        "  test_outcome_df = pd.DataFrame(report).transpose()\n",
        "  test_outcome_df['error_tuple'] = str(errors)\n",
        "  test_outcome_df['random state'] = random_state\n",
        "  test_outcome_df.to_csv(file, mode='a', header=False)"
      ],
      "metadata": {
        "id": "IJcw1AIpH2m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_tuples_list = [[('typo_smart',['review_summary']),\n",
        "                ('typo_naive',['review_summary']),\n",
        "                ('missing',['rented_for']),\n",
        "                ('missing',['age']),\n",
        "                ('missing',['category']),\n",
        "                ('swapping',['weight','height']),\n",
        "                ('swapping',['age','height']),\n",
        "                ('scale',['rating']),\n",
        "                ('scale',['weight']),\n",
        "                ()],\n",
        "                  [('typo_naive',['review_summary'])],\n",
        "                  [('missing',['category'])],\n",
        "                 [()] ]\n",
        "\n",
        "def write_results(error_tuples_list, file, auto):\n",
        "  start_report(file, 'w')\n",
        "  for mod_number in range(len(random_states)):\n",
        "    print(f\"Using random state: {random_states[mod_number]} ({mod_number+1}/{len(random_states)}) \")\n",
        "    model = models[mod_number]\n",
        "    fraction = .5\n",
        "\n",
        "    for error_tuples in error_tuples_list:\n",
        "      errors = []\n",
        "      for error in error_tuples:\n",
        "          if error != ():\n",
        "            errors.append(error)\n",
        "\n",
        "      X_corrupted_test = deepcopy(X_tests[mod_number])\n",
        "      y_corrupted_test = deepcopy(y_tests[mod_number])\n",
        "      print(f\"error list: {errors}\")\n",
        "      #possible error names are defined in inject_error function\n",
        "\n",
        "      # corrupts the test data and returns the classification report\n",
        "      report = corrupt_and_fix(model, errors, X_corrupted_test, y_corrupted_test, X_trains[mod_number], y_trains[mod_number], auto=auto, verbose=False)\n",
        "      print(report)\n",
        "      # save results to file\n",
        "      append_report(report, file, random_states[mod_number], errors)\n",
        "\n",
        "write_results(error_tuples_list,'all_noclean.csv',False)\n",
        "write_results(error_tuples_list,'all_clean.csv',True)"
      ],
      "metadata": {
        "id": "h-hbEOLrlLQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_tuples = [('typo_smart',['review_summary']),\n",
        "                ('typo_naive',['review_summary']),\n",
        "                ('missing',['rented_for']),\n",
        "                ('missing',['age']),\n",
        "                ('missing',['category']),\n",
        "                ('swapping',['weight','height']),\n",
        "                ('swapping',['age','height']),\n",
        "                ('category_mixup',['category']),\n",
        "                ('category_mixup',['bust_size']),\n",
        "                ('scale',['rating']),\n",
        "                ('scale',['weight']),\n",
        "                ()]\n",
        "\n",
        "def write_results(error_tuples, file, auto):\n",
        "  start_report(file, 'w')\n",
        "  for mod_number in range(len(random_states)):\n",
        "    print(f\"Using random state: {random_states[mod_number]} ({mod_number+1}/{len(random_states)}) \")\n",
        "    model = models[mod_number]\n",
        "    fraction = .5\n",
        "\n",
        "    for error in error_tuples:\n",
        "      if error == ():\n",
        "        errors = []\n",
        "      else:\n",
        "        errors = [error]\n",
        "      X_corrupted_test = deepcopy(X_tests[mod_number])\n",
        "      y_corrupted_test = deepcopy(y_tests[mod_number])\n",
        "      print(f\"error list: {errors}\")\n",
        "      #possible error names are defined in inject_error function\n",
        "\n",
        "      # corrupts the test data and returns the classification report\n",
        "      report = corrupt_and_fix(model, errors, X_corrupted_test, y_corrupted_test, X_trains[mod_number], y_trains[mod_number], auto=auto, verbose=False)\n",
        "      print(report)\n",
        "      # save results to file\n",
        "      append_report(report, file, random_states[mod_number], errors)\n",
        "\n",
        "write_results(error_tuples,'noclean.csv',False)\n",
        "write_results(error_tuples,'clean.csv',True)"
      ],
      "metadata": {
        "id": "6i2riCyUZXlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell can be edited to run various experiments.\n",
        "* Specify the list of columns you want to maniplulate in the experiment\n",
        "* Specify the file name where you want to save results to\n",
        "* If you want to append an existing file make sure the line 'start_report(file, 'w')' is commented out (it will overwrite the file)\n",
        "* The first loop loops over all the pretrained models (run the training models cell first)\n",
        "* specifiy fraction parameter\n",
        "* the second nested loop can be edited freely to be made to run the tests you want. It should build the errors list (as specified by the inject error function), copy the correct datasets from the previously created lists and call corrupt_and_proedict once for each test you want to run.\n",
        "* (For testing purposes you can comment out the append_report line aswell )"
      ],
      "metadata": {
        "id": "PWDGHllbMxI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
        "\n",
        "# columns to manipulate\n",
        "columns = ['review_summary']\n",
        "#columns = ['review_text', 'review_summary']\n",
        "\n",
        "\n",
        "print(columns)\n",
        "\n",
        "# file name to save results to\n",
        "file = \"./full_df_no_cleaning.csv\"\n",
        "\n",
        "# comment this out if you only want to append to the file and not write a new header\n",
        "start_report(file, 'w')\n",
        "\n",
        "errors = []\n",
        "for mod_number in range(len(random_states)):\n",
        "\n",
        "  print(f\"Using random state: {random_states[mod_number]} ({mod_number+1}/{len(random_states)}) \")\n",
        "\n",
        "  model = models[mod_number]\n",
        "\n",
        "\n",
        "  fraction = .5\n",
        "  errors = []\n",
        "\n",
        "  # define the error tuples here\n",
        "  for col_number in range(len(random_states)):\n",
        "    errors = [('typo_smart', [columns[col_number]])]\n",
        "\n",
        "    X_corrupted_test = deepcopy(X_tests[mod_number])\n",
        "    y_corrupted_test = deepcopy(y_tests[mod_number])\n",
        "\n",
        "\n",
        "    print(f\"error list: {errors}\")\n",
        "    #possible error names are defined in inject_error function\n",
        "\n",
        "    # corrupts the test data and returns the classification report\n",
        "    report = corrupt_and_fix(model, errors, X_corrupted_test, y_corrupted_test, X_trains[mod_number], y_trains[mod_number], auto=False, verbose=False)\n",
        "\n",
        "    # save results to file\n",
        "    append_report(report, file, random_states[mod_number])\n",
        "\n"
      ],
      "metadata": {
        "id": "pxL4KQDDnz34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Results"
      ],
      "metadata": {
        "id": "GD-H_5ovID0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_test_result(file):\n",
        "  df = pd.read_csv(file)\n",
        "  df.rename(columns={ df.columns[0]: \"type\" }, inplace = True)\n",
        "\n",
        "  df = df.loc[lambda x: x[\"type\"] == \"accuracy\"]\n",
        "  accuracy = (df[\"precision\"]).astype(float)\n",
        "  error_tuple = df[\"error tuple\"]\n",
        "  random_state = df['random state']\n",
        "\n",
        "  accuracy = pd.concat([error_tuple, accuracy, random_state], axis = 1)\n",
        "\n",
        "  grouped_data =accuracy.groupby('error tuple')['precision'].mean().reset_index()\n",
        "\n",
        "  # Plot the average accuracy against the error tuple\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.bar(grouped_data['error tuple'], grouped_data['precision'])\n",
        "\n",
        "  print(grouped_data)\n",
        "\n",
        "\n",
        "  plt.xlabel('Error tuple')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim(np.min(grouped_data['precision'])-0.02, np.max(grouped_data['precision'])+0.02)\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.title('Accuracy vs. Error Tuple Bar graph')\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_test_result('full_df_no_cleaning.csv')"
      ],
      "metadata": {
        "id": "VHelzRhHrerx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_corrupt_vs_clean(clean_file, unclean_file):\n",
        "  clean_df = pd.read_csv(clean_file)\n",
        "  unclean_df = pd.read_csv(unclean_file)\n",
        "\n",
        "  clean_df.rename(columns={ clean_df.columns[0]: \"type\" }, inplace = True)\n",
        "  unclean_df.rename(columns={ unclean_df.columns[0]: \"type\" }, inplace = True)\n",
        "\n",
        "  unclean_df = unclean_df.loc[lambda x: x[\"type\"] == \"accuracy\"]\n",
        "  accuracy = (unclean_df[\"precision\"]).astype(float)\n",
        "  error_tuple = unclean_df[\"error tuple\"].astype(object)\n",
        "  random_state = unclean_df['random state']\n",
        "\n",
        "  unclean_accuracy = pd.concat([error_tuple, accuracy, random_state], axis = 1)\n",
        "\n",
        "  clean_df = clean_df.loc[lambda x: x[\"type\"] == \"accuracy\"]\n",
        "  accuracy = (clean_df[\"precision\"]).astype(float)\n",
        "  error_tuple = clean_df[\"error tuple\"].astype(object)\n",
        "  random_state = clean_df['random state']\n",
        "\n",
        "  clean_accuracy = pd.concat([error_tuple, accuracy, random_state], axis = 1)\n",
        "\n",
        "\n",
        "  grouped_clean_data = clean_accuracy.groupby('error tuple')['precision'].mean().reset_index()\n",
        "  grouped_unclean_data = unclean_accuracy.groupby('error tuple')['precision'].mean().reset_index()\n",
        "\n",
        "  grouped_data = pd.merge(grouped_unclean_data, grouped_clean_data, on='error tuple', how='inner', suffixes = (\"_unclean\", \"_clean\"))\n",
        "\n",
        "  print(grouped_data)\n",
        "\n",
        "  # Plot the average accuracy against the error tuple\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  X = np.arange(len(grouped_data['error tuple']))\n",
        "\n",
        "\n",
        "  plt.bar(X - 0.2, grouped_data['precision_unclean'], 0.4, label=\"Without Autofix\")\n",
        "  plt.bar(X + 0.2, grouped_data['precision_clean'], 0.4, label=\"With Autofix\")\n",
        "\n",
        "\n",
        "  plt.xlabel('Error Tuple' ,fontsize=18, fontweight='bold')\n",
        "  plt.ylabel('Accuracy' ,fontsize=18, fontweight='bold')\n",
        "  plt.ylim(np.max(grouped_data['precision_clean'])-0.02, np.max(grouped_data['precision_clean'])+0.02)\n",
        "  plt.ylim(0.675,0.684)\n",
        "  plt.xticks(X, grouped_data['error tuple'], rotation=90, fontsize = 12)\n",
        "  plt.title('Accuracy vs. Error Tuple Bar Graph', fontsize=18, fontweight='bold')\n",
        "  plt.legend(fontsize = 12)\n",
        "  plt.grid(True)\n",
        "  plt.tick_params(axis='y', labelsize=12)\n",
        "  plt.rcParams.update({'font.size': plt.rcParamsDefault['font.size'],\n",
        "                     'font.weight': plt.rcParamsDefault['font.weight']})\n",
        "  plt.show()\n",
        "\n",
        "plot_corrupt_vs_clean('clean.csv','noclean.csv')"
      ],
      "metadata": {
        "id": "QrNpxsL4so_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}